第4章 ロック
===========

xv6はマルチプロセッサ、複数のCPUが独立してコードを実行する環境下、で動作している。
これらのマルチプロセッサの環境では、CPUは同一の物理アドレスを利用し、データ構造を共有する; xv6はそれぞれが干渉しないようにするためのメカニズムを導入する必要がある。
単一プロセッサでも、xv6はいくつかのメカニズムを利用して、割り込みハンドラが非割り込みハンドラから干渉されることを防ぐために同様のメカニズムを利用する必要がある。
xv6は、どちらにも低レベルの同一の考え方を利用している: 「ロック」である。
ロックは相互実行、つまり複数のCPUのうち、ある時間においてたった一つのCPUがロックを保持するということを保証する機構を提供する。
もしxv6は特定のロックを保持している間しかデータ構造にアクセスしないならば、xv6はそのデータ構造に対してたった一つのCPUのみがアクセスしていることを保証することができる。
このような状況下のことを、私達はデータ構造をロックしている、と呼ぶ。

本章の残りでは、xv6では何故ロックが必要なのか、どのようにしてロックを実装しているのかについて見ていき、これをどのようにして利用するかについて見る。
注目すべきなのは、xv6のコード上でロックを確保するときは、あなたはあなた自身に、他のプロセッサがそのコードの所望の行動を変えられていないかチェックしなければならない、ということである(例えば、他のプロセッサが同一のコード行を実行しているか、他のコード行で変数を変更している可能性がある、ということである)。
また、もし割り込みハンドラが実行されると何が起きるか、ということについても考えなければならない。
どちらのケースでも、単一のCの文は複数のマシン命令に変換され、他のプロセッサや割り込みによって、そのCの文を実行している途中で分断される可能性があるということである。
また、本ページのコード列はシーケンシャルに実行されるとは考えてはいけない、もしくは、単一のCの文がアトミックに実行されるとは考えてはいけない。
並列に動作することによって、プログラムの正確性を推測することはより難しくなるのである。

# レースコンディション
ロックが必要な例として、いくつかのプロセッサが、IDEディスクなどの単一のディスクをxv6上で共有していることを考える。
ディスクドライバのメカニズムは、まだ未実行なディスクリクエストのリンクリストを管理しており(4121行目)、プロセッサは新しいリクエストを、並列にそのリストに追加していく(4254行目)。もしここで並列なリクエストが発生しなければ、リンクリストを以下のように実装することができる:

```
1 struct list {
2 int data;
3 struct list *next;
4 };
5
6 struct list *list = 0;
7
8 void
9 insert(int data)
10 {
11 struct list *l;
12
13 l = malloc(sizeof *l);
14 l->data = data;
15 l->next = list;
16 list = l;
17 }
```

この実装が正しいことを証明するのは、データ構造とアルゴリズムの授業において、典型的な練習問題である。
この実装が正しいと証明されたとしても、少なくともマルチプロセッサ上では正しくない。
もし2つの異なるCPUがinsertを同時に実行開始すると、どちらのコードも16行目を実行する前に15行目を十個うする(図4-1を参照のこと)。
もしこのようなこととが発生すると、listは2つのlのnext値として設定される。
16行目でlistへの代入の文が同時に実行されると、2番目の文は最初の文を上書きする; 最初に代入を実行した分のノードは消失してしまう。
この形の問題は「レースコンディション」と呼ばれる。
このレースの問題は、2つのCPUの厳密なタイミングに依存し、メモリ操作がどのような順番で実行されるかに依存するため、再現することが難しい。
例えば、insertをデバッグ中にprint文を追加すると、タイミングが変わるためこのレース状態が消失してしまう可能性がある。
レースコンディションを回避するための典型的な方法はロックを使うことである。
ロックにより排他実行を保証し、たった1つのCPUが同時にinsertを実行することを保証する; これにより、上記のシナリオが発生することは不可能となる。
以下のコードは、上記のコードにいくつかプログラムを追加した、正しくロック機構を導入したバージョンである(ナンバリングされていない部分が、新たに追加したプログラムである)。

```
6 struct list *list = 0;
struct lock listlock;
7
8 void
9 insert(int data)
10 {
11 struct list *l;
12
acquire(&listlock);
13 l = malloc(sizeof *l);
14 l->data = data;
15 l->next = list;
16 list = l;
release(&listlock);
17 }
```
私達は、データをロックすると言うが、正確にはロックによりデータに適用されるいくつかの不変性が保護されたというのが正しい。
不変性は、データ操作の間に保持されているべきデータの特性である。
典型的に、処理の正しい動作は、その不変式がその処理が開始されたときに真であるかに依存する。
処理は一時的にその不変性を侵害するときがあるが、処理が完了する迄には修復できていなければならない。
例えば、リンクリストのケースは、不変性は変数listがリストの最初のノードを指しており、各ノードのnextフィールドが次のノードを指しているといものである。
insertの実装は、lがリストの最初のノードであるが、lの次のポインタがリストの次のノードを指していない(これにより不変性が崩れるが、15行目で復元される)。
そして、listはlを指してはいない(16行目で修復される)。
私達がチェックしたレースコンディションは上記の部分で発生する。それは、2番目のCPUがリストの不変性が一時的に崩されたときに発生するからである。
ロックの正しい使い方は、ある時間にたった一つのCPUがあるデータ構造を操作し、そのデータ構造の不変性が崩れている最中に他のCPUがそのデータ構造を触らないようにすることである。

# コード例: ロック
xv6はロックをstruct spinlockとして表現する(1501行目)。
データにおいてそれが「ロックされている」というのは、そのワードがゼロであればロックが入手可能であるということで、非ゼロであればロックされているということである。
論理的には、xv6は次のようなコードを実行してxv6はロックを獲得する。

```
21 void
22 acquire(struct spinlock *lk)
23 {
24     for(;;) {
25         if(!lk->locked) {
26             lk->locked = 1;
27             break;
28         }
29     }
30 }
```
残念ながら、上記のコードではマルチプロセッサでの実行中に正しく排他制御を実現できる保証はない。
2つ以上のマルチプロセッサが同時に25行目を実行し、lk->lockedがゼロであることを確認すると、同時に26行目を実行し、27行目に移る。
これにより、2つ以上の異なるCPUがロックを獲得し、排他実行の特性が破られることになってしまう。
レースコンディションを避ける支援を行うというよりかは、上位のacquireの実装自体がレースコンディションを持っている。
上記の問題は、25行目と26行目が別々に実行されることである。
上記のルーチンを正しく実行するためには、25行えと26行目が「アトミック(atomic)」(つまり、分割されることなく)実行されなければならない。

上記の2つの文をアトミックに実行するためには、xv6は386の特別なハードウェア命令,、xchg(0569行目)に頼らなければならない。
1つのアトミックな操作によって、xchgはメモリの内容とレジスタの内容をスワップする。
関数acquire(1574行目)はこのxchg命令をループで繰替えして実行している;各繰り返しでは、lk->lockedを読み込み、アトミックに1を設定する(1583行目)
もしロックが保持されていれば、lk->lockedは既に1であるため、xchgは1を返してループを継続する。
もしxchgが0を返したなば、acquireはロックを正しく獲得に成功したということである -- lockedは0から1に変化する -- そうして、ループは終了する。
ロックが一度獲得されるとacquireはデバッグのためにそれを記録し、CPUとスタックトレースはロックを獲得したことを記録する。
プロセスがロックを獲得しリリースを忘れると、その情報により犯人を特定する。
このようなデバッグフィールドは、ロックによって保護されており、ロックが確保されているときにしか編集することができない。

release関数(1602行目)はacquireの逆である: デバッグフィールドをクリアし、ロックを解放する。

# モジュール性と再帰ロック

システムデザインでは、クリーンな、モジュールを用いた抽象化を行っていかなければらない: 特定の機能について、呼び出し元が、呼び出し先の実装がどのような実装になっているのかについて知る必要が無いのがベストである。
ロックは、このモジュール性を邪魔するものである。
例えば、CPUがいいのロックを保持していたとすると、そのロックを獲得しようとする任意の関数fは呼び出すことができない: 何故ならば、fがあるロックを獲得しようとすると、呼び出し元はfが戻るまで同一のロックを解放することができず、これは永遠にスピンし続けるか、デッドロックを引き起す。

呼び出し元と呼び出し先でロックの情報を隠すという方法は透明性の無い解決法である。
ある共通の、透明性のあるが、不完全な回答は「再帰ロック(recursive lock)」を用い、呼び出し元により確保されたロックをさらに獲得することができるようにする方法である。
この方法の問題は、不変性の保護には利用できないということである。
insertがacquire(&listlock)を呼び出した後は、このロックを他の関数が確保することはないと仮定しており、他のどのような関数も上記の操作を行っている最中ではないという仮定であり、さらに重要なことに、全てのリストが不変性を保持しているということである。
再帰ロックを持ったシステムでは、insertはacquireを実行した後は何も発生しないというように仮定できる: おそらく、insertの呼び出し元が既にロックを保持しておりリストデータ構造を編集中であるときのみ、acquireは成功する。xxx
不変性は、保持しているか、そうでないかのどちらかである。
リストは、もはやそれらを保護しない。
ロックは呼び出し元と呼び出し先が互いに異なるCPUを互いに保護するときに重要である; 再帰ロックはこの特徴を諦める。

明快な解決法は存在しないため、関数の使用としてロックを考える。
プログラマは関数はfが必要なロックを保持している関数fを起動しないように調整する必要がある。
ロックは、これらを強制的に私達の抽象化の世界へ引きずり込むものなのである。
