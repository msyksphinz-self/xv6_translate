第5章 スケジューリング
==================

どのようなオペレーティングシステムも、コンピュータが持っているプロセッサの数以上のプロセスを実行し、従ってプロセス間で時分割共有することが必要になる。
理想的には、ユーザプロセスからはこの共有は見えないようにするべきである。
共通のアプローチとしては、各プロセスが個々に仮想マシンを保持しているように見せ掛け、オペレーティングシステムが複数の仮想マシンを単一のプロセッサで時分割共有して実行することである。
本性ではxv6がどのようにして複数のプロセスをプロセッサ上で実行しているのかについて説明する。

# 多重化

xv6は各プロセッサがあるプロセスから他のプロセスに切り替えることで多重化を行うが、これには2つの状態がある。
最初に、xv6は、あるプロセスがデバイスやパイプI/Oの完了を待つために待ち状態になると、sleepとwakeupの2つのメカニズムにより切り替えを行うか、子供が終了するのを待つか、sleepシステムコールによって終了するのを待つ。
次に、xv6がユーザ命令を実行中に、定期的に強制的に切り替えを行う。
この多重化により、各プロセスは自分のCPUを持っているように見えるが、xv6がメモリアロケータとハードウェアページテーブルにより各プロセスの固有のメモリを持っているように見せ掛けているだけである。

多重化を実装するには、いくつか困難な点がある。
最初に、あるプロセスからどのようにして別のプロセスに切り替えるのか？
xv6はコンテキストスイッチングの標準的なメカニズムを利用している; しかしアイデアはシンプルで、実装はシステムにおいて最も不透明である。
2番目に、どのようにして透過的なコンテキストスイッチングを実現するのか？
xv6は標準的なタイマ割り込みハンドラによりコンテキストスイッチを駆動している。
3番目に、多くのCPUはプロセスを同時に切り替えており、従ってレースコンディションを避けるためにロックの機構も考える必要がある。
4番目に、プロセスが終了したときに、そのメモリと資源を開放しなければならないが、しかしそれを自分自身では実行できない。
何故ならば、(例えば)自分が利用しているのに自分のカーネルスタックを開放することはできない。
xv6はこの問題をなるべくシンプルな方法で解決しようとしているが、結果として得られるコードはトリッキーである。

xv6はプロセスが自分自身を調整することのできる方法を提供しなければならない。
例えば、親プロセスはその子プロセスが終了するまで待つか、他のプロセスがパイプへの書き込みを行うのを待たなければならない。
プロセスが、所望のイベントが発生しているかチェックするためにCPUを無駄に利用するよりも、xv6はCPUの利用を諦めてイベントが発生するまでは眠っておき、他のプロセスが最初のプロセスを起動したほうが良い。
イベントの通知を読み落とすことを避けるために、レースコンディションを避けるためのケアが必要になる。
この問題と解答の例として、本章ではパイプの実装について取り扱う。

# コード例: コンテキストスイッチング

図5-1に示すように、プロセス間で切り替えを行うためには、xv6は低レイヤにおいて2種類のコンテキストスイッチを行っている: プロセスのカーネルスレッドから現在のCPUのスケジューラスレッドへの切り替えと、スケジューラスレッドからプロセスのカーネルスレッドへの切り替えである。
xv6は、決してあるユーザ空間のプロセスから他のプロセスへ直接切り替えすることはない; ところで、この状況はユーザカーネルの変換(システムコールもしくは割り込み)によって発生することはあるが、スケジューラへのコンテキストスイッチ、新しいプロセスのカーネルスレッドへのコンテキストスイッチ、およびトラップにより帰るxxx。
本章ではこのメカニズムの説明として、カーネルスレッドとスケジューラスレッドを取り扱う。

第2章で見てきたように、全てのxv6のプロセスは自分自身のカーネルスタックとレジスタセットを持っている。
各CPUは任意のプロセスのカーネルスレッド向けではなく、スケジューラを実行するための、分離したスケジューラスレッドを持っている。
ある1つのスレッドから他のスレッドに切り替えるために、古いスレッドのCPUレジスタを対比し、新しいスレッドのレジスタを復帰させるという処理が発生する;
%espと%eipが保存と回復が実行され、CPUがスタックをスイッチして、実行しているコードもスイッチしていることを意味する。

swtchはスレッドのことを直接知っているわけではない;contextsと呼ばれるレジスタセットの保存と復帰を行う処理を実行しているだけである。
プロセスがCPUを使うことを諦めると、プロセスのカーネルスレッドがswtchを予備、自身のコンテキストを退避してスケジューラコンテキストへと飛ぶ。
各コンテキストはstruct context*として表現されており、関連するカーネルスタックの構造体のポインタとして表現されている。
swtchは2つの引数を取る; struct context \*\*old とstruct context \*new である。
swtchは現在のCPUレジスタをスタックに保存して、スタックのポインタを\*oldに保存する。
次に、swtchはnewを%espにコピーし、前の保存したレジスタをポップしてから関数から戻る。

swtch内を見てスケジューラを追いかける代わりに、私たちのユーザプロセスが復帰するところを見てみよう。
第3章において、各割り込みの最後にtrapがyieldを呼び出す可能性があることについて触れた。
yieldはschedを呼び出し、schedはproc->contextに入っている現在のコンテキストを保存してcpu->schedulerによって保存している過去のスケジューラコンテキストにスイッチする(2766行目)。

swtch(2952行目)はまずスタックから引数をロードして、それを%eaxと%edx(2959-2960行目)に格納する;
swtchはスタックポインタを変更して%espを通じてどこにもアクセスできなくなる前にこれを実行する必要がある。
次に、swtchはレジスタステートを歩Zん市、現在のスタック上にコンテキスト構造体を作成する。
呼び出し先が保存するレジスタは保存する必要がある; x86はebp,%ebx,%esi,%ebp,%espが対象である。
swtchは最初の4つのレジスタを明示的にプッシュする(2963-2966行目); 最後のレジスタは、\*oldにstruct context*を書き込むことによって暗黙的に保存される。
さらに、もう一つ重要なレジスタが存在する: プログラムカウンタ%eipはswtchを呼び出すcallにより保存され、%ebpのスタックの上に格納される。
古いコンテキストを保存することによって、swtchは新しいコンテキストをロードする準備が整う。
swtchはポインタを新しいコンテキストのスタックポインタに移す(2970行目)。
新しいスタックはswtchが保存した古いスタックのもとの構造的には一緒である - 新しいスタックは前のswtchが呼ばれたときは古いスタックだったのである - したがって、swtchは
新しいコンテキストを退避する手順を逆に踏んでいけばよい。
%edi,%esi,%ebx,%ebpをポップし、買えされた命令アドレスは新しいコンテキストのものである。

私たちの例では、schedはswtchを呼び出してcpu->schedulerにスイッチして、CPU毎のスケジューラコンテキストにスイッチする。
コンテキストはschedulerにより保存され、swtchが呼ばれる(2728行目)。
swtchがどこに戻るかをトレースして言ったとき、schedには戻らずにschedulerに戻る。
スタックポインタは現在のCPUのスケジューラタスクを指しており、initprocのカーネルスタックを指しているわけではない。


# コード例: スケジューリング

前章では、swtchの低レイヤの詳細について確認した; では、swtchを例に取り、あるプロセスからスケジューラに移り、さらにプロセスに移るための慣習について見ていこう。
CPUの使用を取り止めたいプロセスは、プロセステーブルロックであるptable.lockを取得し、現在保持している全てのロックをリリーすし、現在の状態(proc->state)を更新し、schedを呼ぶ。
yield(2772)はこの慣習に従い、sleep命令とexit命令を実行する。これらについては後に見ることにする。
schedはこれらの状態の二重チェックを行い(2757-2762行目)、これらの状態のimplication(xxx)を行う:何故ならば、ロクを獲得すると、CPUは割り込みを無効にして実行するべきだからである。
最後に、schedjhalswtchを呼び、proc->contextの現在のコンテキストを保存して、cpu->schedulerにより保持されているスケジューラコンテキストにスイッチする(2728行目)。
スケジューラはforループを実行し続け、実行できるプロセスを見つけ、スイッチングすることを続ける。

xv6がはswtchを呼び出している間、ptable.lockを保持するところを見た: swtchの呼び出し元は既にこのロックを獲得している必要があり、ロックの制御はコードのスイッチングに渡される。
この慣習はロックにとって通常のことではない; 典型的な慣習は、ロックを獲得したスレッドがロックの解放の責任を持つことであり、これは正しさを保証するためには当然のことである。
コンテキストスイッチングのためには、典型的な慣習を破壊する必要がある。
何故ならば、ptable.lockは、swtchを実行中には真ではないプロセスの状態とcontextフィールドの不変性を保護しているからである。
ptable.lockがswtchの間中保持されていなかった場合に発生する問題の例を示す: 異なるCPUが、yieldが状態をRUNNABLEに変更した後に、どのプロセスを実行するかを来める必要があるが、swtchを呼ぶ前にカーネルスタックを使うことを止める。
この結果により、同一のスタック上で実行している2つのCPUの実行状態を、正しく設定することができなくなる。

カーネルスレッドは、schedの中でいつもプロセッサの利用を止め、スケジューラ中の同一の場所にスイッチし、sched内で(殆ど)常にプロセスにスイッチする。
従って、もしxv6がスレッドをスイッチした行番号をプリントすると、以下のようなシンプルなパタンが存在するはずである(2728行目),(2766行目)、(2728行目)、(2766行目)である。
このような形式で2つのスレッドがスイッチングを発生させることを、「コルーチン」と読んでいる;この例では、schedとschedulerがそろぞれコルーチンである。

新しいプロセスがsched内で終了しない例がある。
第2章で見たように、新しいプロセスが最初にスケジュールされたときである。新しいプロセスは、forkret(2783行目)から実行を開始する。
forkretはptable.lockを解放することで、この慣習を守るための存在している; そうでなければ、新しいプロセスはtrapretからスタートすることになる。

scheduler(2708行目)は単純なループを実行する: 実行可能なプロセスを見つけ、それが停止するまで実行することを繰替えす。
schedulerは殆ど全ての動作中に、ptable.lockのロックを保持しているが、各繰り返しにおいて、ループの外に出るときだけロックを解放する(そして、明示的に割り込みを許可する)。
これは、CPUがアイドル状態のとき(RUNNABLEなプロセスを発見することができなかったとき)に重要である。
アイドル状態のスケジューラがロックを保持し続けていると、プロセスを実行している他のCPUがコンテキストスイッチや、システムコールに関連するプロセスを実行したり、さらに特にプロセスをRUNNABLEに設定する操作ができず、遊休状態のCPUが二度とスケジューリングできなくなってしまう。
定期的に割り込みを許可する理由は、アイドル中のCPUで、例えばシェルのようなI/O待ちの状態でRUNNABLEのプロセスが存在しない場合のためである;
もしスケジューラが割り込みを常に不許可にしていた場合、I/Oの割り込みはもう二度と発生しなくなってしまう。

スケジューラはテーブルを参照しながら、p->state==RUNNABLEであるプロセス、つまり実行可能な状態にあるプロセスを探し続ける。
プロセスをはっけん すると、CPU毎の現在のプロセスの変数であるprocを設定し、プロセスのページテーブルをswitchuvmによりスイッチし、プロセスがRUNNNIGであると設定し、swtchを実行してプロセスの実行を開始する(2722-2728行目)。

スケジューリングのコードの構造について考えるための一つの方法は、各プロセスが常に不変性を維持するように調整されているとして、その不変性が真でなくなるときは常にptable.lockが保持されていると考えることである。
不変性の一つは、もしプロセスがRUNNING状態であれば、実行状態は整っており、タイマー割り込みのyieldは正しくプロセスからスイッチすることができる; これは、CPUのレジスタがそのプロセスの値を帆いしており(例えば、それらは実際にはcontextの中には存在しない)、%cr3はプロセスのページテーブルを参照しており、%espはプロセスのカーネルスタックを参照してなければならず、従って、swtchはレジスタを正しくプッシュしており、procはプロセスのproc[]スロットを参照していなければならない。
他の不変性は、もしプロセスがRUNNABLEであれば、アイドル状態のCPUでは、スケジューラを実行することができる; p->contextはプロセスのカーネルスレッドの値を持っており、プロセスのカーネルスタックを実行しているCPUは存在せず、CPUの%cr3はプロセスのページテーブルを参照しておらず、CPUのprocはプロセスを参照してはいない。

上記の不変性を管理することが、xv6がptable.lockを1つのスレッド(しばしばyieldの中)で獲得し、異なるスレッド(スケーウラスレッドもしくは他の次のカーネルスレッド)で解放する理由である。
実行しているプロセスの状態をRUNNABLEに設定するための変更が始まると、その不変性が修正されるまでは、lockを保持していなければならない： 最短の正しい解放ポイントは、schedulerがプロセスのページテーブルを使用するのを止め、procをクリアするところである。
同様に、一度schedulerが実行状態のプロセスをRUNNINGに変更する場合は、カーネルスレッドが完全に実行する状態になるまで(swtchをを実行してから、例えばyieldの中で)ロックは解放することができない。

ptable.lockは同様に、他の部分についても保護を行っている: プロセスのIDの割り当てと、プロセスのテーブルの解放処理と、exitとwaitの相互作用と、wakeupのロストを避けるための手続き(次章を参照のこと)と、他にも様々なことに利用される。
ptable.lockの他の機能について考えることは、明確性については確実に、性能についてはおそらく、分割して考えることが価値のあることになるxxx。
